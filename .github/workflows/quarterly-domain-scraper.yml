name: Quarterly Domain Scraper

on:
  schedule:
    # Run on 15th of Jan, Apr, Jul, Oct at 00:00 UTC
    # This allows time for quarter-end data to be available
    - cron: '0 0 15 1,4,7,10 *'
  workflow_dispatch:  # Allow manual trigger from GitHub UI
    inputs:
      quarter:
        description: 'Quarter to scrape (format: YYYY-Q{1-4}, e.g., 2025-Q1)'
        required: false
        type: string

jobs:
  scrape:
    name: Scrape Domain.com.au Listings
    runs-on: ubuntu-latest
    timeout-minutes: 360  # 6 hours max (GitHub Actions limit)
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          cache: 'pip'
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            chromium-browser \
            chromium-chromedriver
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Determine quarter
        id: quarter
        run: |
          if [ -n "${{ github.event.inputs.quarter }}" ]; then
            # Manual trigger with specified quarter
            QUARTER="${{ github.event.inputs.quarter }}"
          else
            # Scheduled run - determine current quarter
            MONTH=$(date +%m)
            YEAR=$(date +%Y)
            
            if [ "$MONTH" -ge 1 ] && [ "$MONTH" -le 3 ]; then
              Q="Q1"
            elif [ "$MONTH" -ge 4 ] && [ "$MONTH" -le 6 ]; then
              Q="Q2"
            elif [ "$MONTH" -ge 7 ] && [ "$MONTH" -le 9 ]; then
              Q="Q3"
            else
              Q="Q4"
            fi
            
            # For scheduled runs, scrape the previous quarter
            # (since we run on 15th, previous quarter data is more complete)
            if [ "$MONTH" -eq 1 ]; then
              # January 15th -> scrape Q4 of previous year
              YEAR=$((YEAR - 1))
              Q="Q4"
            elif [ "$MONTH" -eq 4 ]; then
              # April 15th -> scrape Q1
              Q="Q1"
            elif [ "$MONTH" -eq 7 ]; then
              # July 15th -> scrape Q2
              Q="Q2"
            elif [ "$MONTH" -eq 10 ]; then
              # October 15th -> scrape Q3
              Q="Q3"
            fi
            
            QUARTER="${YEAR}-${Q}"
          fi
          
          echo "quarter=${QUARTER}" >> $GITHUB_OUTPUT
          echo "Scraping quarter: ${QUARTER}"
      
      - name: Run Domain Scraper
        env:
          # Set display for headless browser
          DISPLAY: :99
        run: |
          # Start virtual display for Selenium
          sudo Xvfb :99 -screen 0 1024x768x24 > /dev/null 2>&1 &
          
          # Run scraper
          python scripts/recurring/domain_live_scraper.py \
            --quarter "${{ steps.quarter.outputs.quarter }}" \
            --output-dir data/
      
      - name: Check scrape results
        id: results
        run: |
          QUARTER="${{ steps.quarter.outputs.quarter }}"
          YEAR=$(echo $QUARTER | cut -d'-' -f1)
          Q=$(echo $QUARTER | cut -d'-' -f2)
          
          if [ "$Q" = "Q1" ]; then
            MONTH="03"
          elif [ "$Q" = "Q2" ]; then
            MONTH="06"
          elif [ "$Q" = "Q3" ]; then
            MONTH="09"
          else
            MONTH="12"
          fi
          
          OUTPUT_FILE="data/landing/domain/live/${YEAR}/${Q}/rental_listings_${YEAR}_${MONTH}.csv"
          
          if [ -f "$OUTPUT_FILE" ]; then
            FILE_SIZE=$(stat -f%z "$OUTPUT_FILE" 2>/dev/null || stat -c%s "$OUTPUT_FILE" 2>/dev/null)
            LINE_COUNT=$(wc -l < "$OUTPUT_FILE" || echo "0")
            echo "file_size=${FILE_SIZE}" >> $GITHUB_OUTPUT
            echo "line_count=${LINE_COUNT}" >> $GITHUB_OUTPUT
            echo "✅ Scrape successful: ${OUTPUT_FILE}"
            echo "   Size: ${FILE_SIZE} bytes"
            echo "   Lines: ${LINE_COUNT}"
          else
            echo "❌ Output file not found: ${OUTPUT_FILE}"
            exit 1
          fi
      
      - name: Commit results
        if: success()
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          
          QUARTER="${{ steps.quarter.outputs.quarter }}"
          git add data/landing/domain/live/
          git diff --staged --quiet || git commit -m "Scrape Domain listings: ${QUARTER} [skip ci]"
          git push
      
      - name: Create summary
        if: always()
        run: |
          QUARTER="${{ steps.quarter.outputs.quarter }}"
          echo "## Scraping Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Quarter**: ${QUARTER}" >> $GITHUB_STEP_SUMMARY
          if [ "${{ steps.results.outputs.file_size }}" != "" ]; then
            echo "- **File Size**: ${{ steps.results.outputs.file_size }} bytes" >> $GITHUB_STEP_SUMMARY
            echo "- **Listings**: ${{ steps.results.outputs.line_count }}" >> $GITHUB_STEP_SUMMARY
          fi
          echo "- **Status**: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY

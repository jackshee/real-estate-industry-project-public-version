{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db79881a",
   "metadata": {},
   "source": [
    "## Preprocessing for School Location Database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2323c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "school_locations_2023.csv: ['Address_Line_1', 'Address_Line_2', 'Address_Postcode', 'Address_State', 'Address_Town', 'Education_Sector', 'Entity_Type', 'Full_Phone_No', 'LGA_ID', 'LGA_Name', 'Postal_Address_Line_1', 'Postal_Address_Line_2', 'Postal_Postcode', 'Postal_State', 'Postal_Town', 'School_Name', 'School_No', 'School_Status', 'School_Type', 'X', 'Y']\n",
      "school_locations_2025.csv: ['Address_Line_1', 'Address_Line_2', 'Address_Postcode', 'Address_State', 'Address_Town', 'Area', 'Education_Sector', 'Entity_Type', 'Full_Phone_No', 'LGA_ID', 'LGA_Name', 'LGA_TYPE', 'Postal_Address_Line_1', 'Postal_Address_Line_2', 'Postal_Postcode', 'Postal_State', 'Postal_Town', 'Region', 'School_Name', 'School_No', 'School_Status', 'School_Type', 'X', 'Y']\n",
      "school_locations_2024.csv: ['AREA_Name', 'Address_Line_1', 'Address_Line_2', 'Address_Postcode', 'Address_State', 'Address_Town', 'Education_Sector', 'Entity_Type', 'Full_Phone_No', 'LGA_ID', 'LGA_Name', 'Postal_Address_Line_1', 'Postal_Address_Line_2', 'Postal_Postcode', 'Postal_State', 'Postal_Town', 'Region_Name', 'School_Name', 'School_No', 'School_Type', 'X', 'Y']\n",
      "\n",
      "Schemas match: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing the school CSV files\n",
    "schools_dir = '../data/landing/schools'\n",
    "\n",
    "# List all CSV files in the directory\n",
    "csv_files = [f for f in os.listdir(schools_dir) if f.endswith('.csv')]\n",
    "\n",
    "# Load each CSV and collect their columns\n",
    "schemas = {}\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(os.path.join(schools_dir, file), nrows=0, encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        df = pd.read_csv(os.path.join(schools_dir, file), nrows=0, encoding='latin1')\n",
    "    schemas[file] = set(df.columns)\n",
    "\n",
    "# Display the columns for each file\n",
    "for file, cols in schemas.items():\n",
    "    print(f\"{file}: {sorted(cols)}\")\n",
    "\n",
    "# Check if all schemas match\n",
    "all_schemas = list(schemas.values())\n",
    "schemas_match = all(s == all_schemas[0] for s in all_schemas)\n",
    "print(f\"\\nSchemas match: {schemas_match}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb20d197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the standardized schema based on common columns across all years\n",
    "standard_columns = [\n",
    "    'Address_Line_1', 'Address_Line_2', 'Address_Postcode', 'Address_State', 'Address_Town',\n",
    "    'Education_Sector', 'Entity_Type', 'Full_Phone_No', 'LGA_ID', 'LGA_Name',\n",
    "    'Postal_Address_Line_1', 'Postal_Address_Line_2', 'Postal_Postcode', 'Postal_State', 'Postal_Town',\n",
    "    'School_Name', 'School_No', 'School_Type', 'X', 'Y',\n",
    "    # Additional columns that exist in some years\n",
    "    'Area', 'LGA_TYPE', 'Region', 'School_Status'\n",
    "]\n",
    "\n",
    "print(\"Standardized schema:\")\n",
    "for col in standard_columns:\n",
    "    print(f\"  - {col}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc144f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to standardize column names and add missing columns\n",
    "def standardize_school_dataframe(df, year):\n",
    "    \"\"\"\n",
    "    Standardize a school dataframe to have consistent columns.\n",
    "    \n",
    "    Parameters:\n",
    "    df: pandas DataFrame\n",
    "    year: string indicating the year (2023, 2024, or 2025)\n",
    "    \n",
    "    Returns:\n",
    "    pandas DataFrame with standardized columns\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original\n",
    "    df_std = df.copy()\n",
    "    \n",
    "    # Handle column name variations\n",
    "    column_mapping = {\n",
    "        'AREA_Name': 'Area',  # 2024 has AREA_Name instead of Area\n",
    "        'Region_Name': 'Region'  # 2024 has Region_Name instead of Region\n",
    "    }\n",
    "    \n",
    "    # Rename columns\n",
    "    df_std = df_std.rename(columns=column_mapping)\n",
    "    \n",
    "    # Add missing columns with NaN values\n",
    "    for col in standard_columns:\n",
    "        if col not in df_std.columns:\n",
    "            df_std[col] = None\n",
    "    \n",
    "    # Reorder columns to match standard schema\n",
    "    df_std = df_std[standard_columns]\n",
    "    \n",
    "    # Add year column to indicate when school was established\n",
    "    df_std['establishment_year'] = year\n",
    "    \n",
    "    return df_std\n",
    "\n",
    "# Test the function with a small sample\n",
    "print(\"Testing standardization function...\")\n",
    "for file in csv_files:\n",
    "    year = file.split('_')[-1].split('.')[0]  # Extract year from filename\n",
    "    print(f\"\\nProcessing {file} (year: {year})\")\n",
    "    \n",
    "    # Load a small sample to test\n",
    "    try:\n",
    "        df_sample = pd.read_csv(os.path.join(schools_dir, file), nrows=5, encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        df_sample = pd.read_csv(os.path.join(schools_dir, file), nrows=5, encoding='latin1')\n",
    "    \n",
    "    # Standardize\n",
    "    df_std = standardize_school_dataframe(df_sample, year)\n",
    "    \n",
    "    print(f\"Original columns: {len(df_sample.columns)}\")\n",
    "    print(f\"Standardized columns: {len(df_std.columns)}\")\n",
    "    print(f\"Missing columns added: {[col for col in standard_columns if col not in df_sample.columns]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c197ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and standardize all school datasets\n",
    "print(\"Loading and standardizing all school datasets...\")\n",
    "standardized_dfs = []\n",
    "\n",
    "for file in csv_files:\n",
    "    year = file.split('_')[-1].split('.')[0]  # Extract year from filename\n",
    "    print(f\"\\nProcessing {file} (year: {year})\")\n",
    "    \n",
    "    # Load the full dataset\n",
    "    try:\n",
    "        df = pd.read_csv(os.path.join(schools_dir, file), encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        df = pd.read_csv(os.path.join(schools_dir, file), encoding='latin1')\n",
    "    \n",
    "    print(f\"  Loaded {len(df)} schools\")\n",
    "    \n",
    "    # Standardize the dataframe\n",
    "    df_std = standardize_school_dataframe(df, year)\n",
    "    standardized_dfs.append(df_std)\n",
    "    \n",
    "    print(f\"  Standardized to {len(df_std.columns)} columns\")\n",
    "\n",
    "# Combine all standardized dataframes\n",
    "print(f\"\\nCombining {len(standardized_dfs)} datasets...\")\n",
    "combined_schools = pd.concat(standardized_dfs, ignore_index=True)\n",
    "\n",
    "print(f\"Combined dataset shape: {combined_schools.shape}\")\n",
    "print(f\"Total schools: {len(combined_schools)}\")\n",
    "print(f\"\\nEstablishment year distribution:\")\n",
    "print(combined_schools['establishment_year'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01ee3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample of the combined dataset\n",
    "print(\"Sample of combined dataset:\")\n",
    "print(combined_schools[['School_Name', 'School_Type', 'Address_Town', 'establishment_year']].head(10))\n",
    "\n",
    "print(f\"\\nData types:\")\n",
    "print(combined_schools.dtypes)\n",
    "\n",
    "print(f\"\\nMissing values per column:\")\n",
    "missing_values = combined_schools.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e8dca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the combined dataset\n",
    "output_path = '../data/processed/schools/combined_schools_standardized.csv'\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "combined_schools.to_csv(output_path, index=False)\n",
    "print(f\"Combined dataset saved to: {output_path}\")\n",
    "\n",
    "# Also save a summary\n",
    "summary_path = '../data/curated/schools/schools_summary.txt'\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(\"Schools Dataset Summary\\n\")\n",
    "    f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "    f.write(f\"Total schools: {len(combined_schools)}\\n\")\n",
    "    f.write(f\"Columns: {len(combined_schools.columns)}\\n\\n\")\n",
    "    f.write(\"Establishment year distribution:\\n\")\n",
    "    for year, count in combined_schools['establishment_year'].value_counts().sort_index().items():\n",
    "        f.write(f\"  {year}: {count} schools\\n\")\n",
    "    f.write(f\"\\nMissing values:\\n\")\n",
    "    missing_values = combined_schools.isnull().sum()\n",
    "    for col, count in missing_values[missing_values > 0].items():\n",
    "        f.write(f\"  {col}: {count} missing\\n\")\n",
    "\n",
    "print(f\"Summary saved to: {summary_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5045eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

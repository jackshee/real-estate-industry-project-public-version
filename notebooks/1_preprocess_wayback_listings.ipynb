{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8470fe2",
   "metadata": {},
   "source": [
    "This notebook performs basic preprocessing for the wayback scraped listings. It also sets up intermediate files required calling GeoCode API via Open Route Service. The results from running this notebook are saved to `data/processed/domain/wayback_listings.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8810b826",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "388029be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50dd0157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenRouteService client initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "from utils.preprocess import PreprocessUtils\n",
    "from utils.geo import GeoUtils\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Initialize the preprocessor\n",
    "preprocessor = PreprocessUtils()\n",
    "\n",
    "# Initialize the geo utils\n",
    "geo_utils = GeoUtils()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff330793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14 files to process:\n",
      "  - rental_listings_2022_03.csv\n",
      "  - rental_listings_2022_06.csv\n",
      "  - rental_listings_2022_09.csv\n",
      "  - rental_listings_2022_12.csv\n",
      "  - rental_listings_2023_03.csv\n",
      "  - rental_listings_2023_06.csv\n",
      "  - rental_listings_2023_09.csv\n",
      "  - rental_listings_2023_12.csv\n",
      "  - rental_listings_2024_03.csv\n",
      "  - rental_listings_2024_06.csv\n",
      "  - rental_listings_2024_09.csv\n",
      "  - rental_listings_2024_12.csv\n",
      "  - rental_listings_2025_03.csv\n",
      "  - rental_listings_2025_06.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the domain folder\n",
    "domain_path = \"../data/raw/domain\"\n",
    "\n",
    "# Get all CSV files except rental_listings_2025_09.csv\n",
    "csv_files = glob.glob(os.path.join(domain_path, \"rental_listings_*.csv\"))\n",
    "csv_files = [f for f in csv_files if \"rental_listings_2025_09.csv\" not in f]\n",
    "\n",
    "print(f\"Found {len(csv_files)} files to process:\")\n",
    "for f in sorted(csv_files):\n",
    "    print(f\"  - {os.path.basename(f)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf84301f",
   "metadata": {},
   "source": [
    "Here we make the assumption that the listings on wayback have an `updated_dated` that is equal to the `scraped_date`. Because we scraped a random day with an existing snapshot for each suburb in each quarter going back to 2022 Q1, we essentially have more rental price data for listings last updated in the \"past\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9ec82f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded rental_listings_2022_03.csv: 20 rows, Year=2022, Quarter=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded rental_listings_2022_06.csv: 3047 rows, Year=2022, Quarter=2\n",
      "Loaded rental_listings_2022_09.csv: 710 rows, Year=2022, Quarter=3\n",
      "Loaded rental_listings_2022_12.csv: 23 rows, Year=2022, Quarter=4\n",
      "Loaded rental_listings_2023_03.csv: 123 rows, Year=2023, Quarter=1\n",
      "Loaded rental_listings_2023_06.csv: 98 rows, Year=2023, Quarter=2\n",
      "Loaded rental_listings_2023_09.csv: 20 rows, Year=2023, Quarter=3\n",
      "Loaded rental_listings_2023_12.csv: 179 rows, Year=2023, Quarter=4\n",
      "Loaded rental_listings_2024_03.csv: 1372 rows, Year=2024, Quarter=1\n",
      "Loaded rental_listings_2024_06.csv: 1786 rows, Year=2024, Quarter=2\n",
      "Loaded rental_listings_2024_09.csv: 1460 rows, Year=2024, Quarter=3\n",
      "Loaded rental_listings_2024_12.csv: 1562 rows, Year=2024, Quarter=4\n",
      "Loaded rental_listings_2025_03.csv: 3340 rows, Year=2025, Quarter=1\n",
      "Loaded rental_listings_2025_06.csv: 3382 rows, Year=2025, Quarter=2\n",
      "\n",
      "Total dataframes loaded: 14\n"
     ]
    }
   ],
   "source": [
    "# Read all CSV files and add year and quarter columns\n",
    "dataframes = []\n",
    "\n",
    "for csv_file in sorted(csv_files):\n",
    "    # Extract filename without extension\n",
    "    filename = os.path.basename(csv_file)\n",
    "    # Parse filename: rental_listings_YYYY_MM.csv\n",
    "    parts = filename.replace('.csv', '').split('_')\n",
    "    year = parts[2]\n",
    "    month = parts[3]\n",
    "    \n",
    "    # Map month to quarter\n",
    "    month_to_quarter = {\n",
    "        '03': 1,\n",
    "        '06': 2,\n",
    "        '09': 3,\n",
    "        '12': 4\n",
    "    }\n",
    "    quarter = month_to_quarter.get(month, 'Unknown')\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Add year and quarter columns\n",
    "    df['year'] = int(year)\n",
    "    df['quarter'] = quarter\n",
    "    \n",
    "    dataframes.append(df)\n",
    "    print(f\"Loaded {filename}: {len(df)} rows, Year={year}, Quarter={quarter}\")\n",
    "\n",
    "print(f\"\\nTotal dataframes loaded: {len(dataframes)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b875fa0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17122 entries, 0 to 17121\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   property_id        17122 non-null  int64  \n",
      " 1   url                17122 non-null  object \n",
      " 2   rental_price       17122 non-null  object \n",
      " 3   bedrooms           16994 non-null  float64\n",
      " 4   bathrooms          17067 non-null  float64\n",
      " 5   car_spaces         15120 non-null  float64\n",
      " 6   property_type      17122 non-null  object \n",
      " 7   land_area          17122 non-null  float64\n",
      " 8   property_features  17122 non-null  object \n",
      " 9   suburb             17122 non-null  object \n",
      " 10  postcode           17122 non-null  int64  \n",
      " 11  scraped_date       17122 non-null  object \n",
      " 12  wayback_url        17122 non-null  object \n",
      " 13  wayback_time       17122 non-null  int64  \n",
      " 14  year               17122 non-null  int64  \n",
      " 15  quarter            17122 non-null  int64  \n",
      "dtypes: float64(4), int64(5), object(7)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Stack all dataframes together\n",
    "df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7eb9469b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map the suburbs to standardized names (used by DFFH dataset)\n",
    "df['suburb'] = preprocessor.map_suburb(df['suburb'])\n",
    "\n",
    "# Remove the suburbs that have count less than 10\n",
    "suburb_counts = df['suburb'].value_counts()\n",
    "valid_suburbs = suburb_counts[suburb_counts > 10].index\n",
    "df = df[df['suburb'].isin(valid_suburbs)]\n",
    "\n",
    "df['suburb'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac32bd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop land_area column\n",
    "df = df.drop(columns=['land_area'])\n",
    "\n",
    "# convert bedrooms, bathrooms, car_spaces to Int64\n",
    "df['bedrooms'] = df['bedrooms'].astype('Int64')\n",
    "df['bathrooms'] = df['bathrooms'].astype('Int64')\n",
    "df['car_spaces'] = df['car_spaces'].astype('Int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9e24131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before imputation:\n",
      "bedrooms       108\n",
      "bathrooms       42\n",
      "car_spaces    1767\n",
      "dtype: int64\n",
      "Property type: Apartment / Unit / Flat, bedrooms imputed with 2\n",
      "Property type: Townhouse, bedrooms imputed with 3\n",
      "Property type: House, bedrooms imputed with 3\n",
      "Property type: Studio, bedrooms imputed with 1\n",
      "Property type: Duplex, bedrooms imputed with 2\n",
      "Property type: Vacant land, bedrooms imputed with 4\n",
      "Property type: Farm, bedrooms imputed with <NA>\n",
      "Property type: Apartment / Unit / Flat, bathrooms imputed with 1\n",
      "Property type: Townhouse, bathrooms imputed with 2\n",
      "Property type: House, bathrooms imputed with 2\n",
      "Property type: Studio, bathrooms imputed with 1\n",
      "Property type: Vacant land, bathrooms imputed with 2\n",
      "Property type: Farm, bathrooms imputed with <NA>\n",
      "Property type: Apartment / Unit / Flat, car_spaces imputed with 1\n",
      "Property type: Townhouse, car_spaces imputed with 2\n",
      "Property type: House, car_spaces imputed with 2\n",
      "Property type: Studio, car_spaces imputed with 1\n",
      "Property type: New Apartments / Off the Plan, car_spaces imputed with 1\n",
      "Property type: Duplex, car_spaces imputed with 1\n",
      "Property type: Vacant land, car_spaces imputed with 2\n",
      "Property type: Acreage / Semi-Rural, car_spaces imputed with 4\n",
      "Property type: Villa, car_spaces imputed with 1\n",
      "Property type: Unknown, car_spaces imputed with 1\n",
      "Property type: Terrace, car_spaces imputed with 2\n",
      "Property type: New House & Land, car_spaces imputed with 2\n",
      "Property type: Farm, car_spaces imputed with <NA>\n",
      "\n",
      "After imputation:\n",
      "bedrooms      1\n",
      "bathrooms     1\n",
      "car_spaces    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# impute bedrooms, bathrooms, car_spaces with preprocessor\n",
    "# handle missing values by imputing by mode grouped by property_type\n",
    "print(\"Before imputation:\")\n",
    "print(df[['bedrooms', 'bathrooms', 'car_spaces']].isnull().sum())\n",
    "\n",
    "# Impute bedrooms using property_type mode\n",
    "df['bedrooms'] = preprocessor.impute_by_property_type_mode(df, 'bedrooms')\n",
    "\n",
    "# Impute bathrooms using property_type mode\n",
    "df['bathrooms'] = preprocessor.impute_by_property_type_mode(df, 'bathrooms')\n",
    "\n",
    "# Impute car_spaces using property_type mode\n",
    "df['car_spaces'] = preprocessor.impute_by_property_type_mode(df, 'car_spaces')\n",
    "\n",
    "print(\"\\nAfter imputation:\")\n",
    "print(df[['bedrooms', 'bathrooms', 'car_spaces']].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f1b8d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with unknown price frequencies: 351\n"
     ]
    }
   ],
   "source": [
    "# Extract weekly rent from rental_price column\n",
    "df['rental_price'] = preprocessor.extract_rental_price(df['rental_price'])\n",
    "\n",
    "# Check how many rows have unknown frequencies (NaN in weekly_rent)\n",
    "unknown_count = df['rental_price'].isna().sum()\n",
    "print(f\"Rows with unknown price frequencies: {unknown_count}\")\n",
    "\n",
    "# Drop rows with unknown frequencies\n",
    "df = df[df['rental_price'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9fd8e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_id</th>\n",
       "      <th>rental_price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>car_spaces</th>\n",
       "      <th>property_type</th>\n",
       "      <th>suburb</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15295193</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Apartment / Unit / Flat</td>\n",
       "      <td>footscray</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>51 Gordon Street, Footscray, VIC 3011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15624467</td>\n",
       "      <td>385.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Townhouse</td>\n",
       "      <td>footscray</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>Cirque Drive, Footscray, VIC 3011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15726089</td>\n",
       "      <td>470.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>House</td>\n",
       "      <td>footscray</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>10 Stanlake Street, Footscray, VIC 3011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15754757</td>\n",
       "      <td>410.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Apartment / Unit / Flat</td>\n",
       "      <td>footscray</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>42 Whitehall Street, Footscray, VIC 3011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15802091</td>\n",
       "      <td>650.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>House</td>\n",
       "      <td>footscray</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>2 Saltriver Place, Footscray, VIC 3011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17113</th>\n",
       "      <td>13001612</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>House</td>\n",
       "      <td>trafalgar</td>\n",
       "      <td>2025</td>\n",
       "      <td>2</td>\n",
       "      <td>1c Dodemaides, Trafalgar, VIC 3824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17115</th>\n",
       "      <td>17530473</td>\n",
       "      <td>340.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Studio</td>\n",
       "      <td>trafalgar</td>\n",
       "      <td>2025</td>\n",
       "      <td>2</td>\n",
       "      <td>26a Waterloo Road, Trafalgar, VIC 3824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17116</th>\n",
       "      <td>17597533</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>House</td>\n",
       "      <td>trafalgar</td>\n",
       "      <td>2025</td>\n",
       "      <td>2</td>\n",
       "      <td>Princes Way, Trafalgar, VIC 3824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17120</th>\n",
       "      <td>17618453</td>\n",
       "      <td>550.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>House</td>\n",
       "      <td>trafalgar</td>\n",
       "      <td>2025</td>\n",
       "      <td>2</td>\n",
       "      <td>Cross Street, Trafalgar, VIC 3824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17121</th>\n",
       "      <td>17622779</td>\n",
       "      <td>330.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Apartment / Unit / Flat</td>\n",
       "      <td>trafalgar</td>\n",
       "      <td>2025</td>\n",
       "      <td>2</td>\n",
       "      <td>Brown Street, Trafalgar, VIC 3824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15260 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       property_id  rental_price  bedrooms  bathrooms  car_spaces  \\\n",
       "0         15295193         240.0         1          1           1   \n",
       "1         15624467         385.0         2          1           1   \n",
       "2         15726089         470.0         2          1           1   \n",
       "3         15754757         410.0         2          1           1   \n",
       "4         15802091         650.0         3          2           2   \n",
       "...            ...           ...       ...        ...         ...   \n",
       "17113     13001612          70.0         1          1           3   \n",
       "17115     17530473         340.0         1          1           2   \n",
       "17116     17597533         500.0         3          1           2   \n",
       "17120     17618453         550.0         3          2           2   \n",
       "17121     17622779         330.0         1          1           1   \n",
       "\n",
       "                 property_type     suburb  year  quarter  \\\n",
       "0      Apartment / Unit / Flat  footscray  2022        1   \n",
       "1                    Townhouse  footscray  2022        1   \n",
       "2                        House  footscray  2022        1   \n",
       "3      Apartment / Unit / Flat  footscray  2022        1   \n",
       "4                        House  footscray  2022        1   \n",
       "...                        ...        ...   ...      ...   \n",
       "17113                    House  trafalgar  2025        2   \n",
       "17115                   Studio  trafalgar  2025        2   \n",
       "17116                    House  trafalgar  2025        2   \n",
       "17120                    House  trafalgar  2025        2   \n",
       "17121  Apartment / Unit / Flat  trafalgar  2025        2   \n",
       "\n",
       "                                        address  \n",
       "0         51 Gordon Street, Footscray, VIC 3011  \n",
       "1             Cirque Drive, Footscray, VIC 3011  \n",
       "2       10 Stanlake Street, Footscray, VIC 3011  \n",
       "3      42 Whitehall Street, Footscray, VIC 3011  \n",
       "4        2 Saltriver Place, Footscray, VIC 3011  \n",
       "...                                         ...  \n",
       "17113        1c Dodemaides, Trafalgar, VIC 3824  \n",
       "17115    26a Waterloo Road, Trafalgar, VIC 3824  \n",
       "17116          Princes Way, Trafalgar, VIC 3824  \n",
       "17120         Cross Street, Trafalgar, VIC 3824  \n",
       "17121         Brown Street, Trafalgar, VIC 3824  \n",
       "\n",
       "[15260 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract address from url since we don't have the address in the summary listing data\n",
    "df['address'] = df['url'].apply(geo_utils.extract_address_from_url)\n",
    "\n",
    "# drop url column\n",
    "df = df.drop(columns=['url', 'property_features', 'postcode', 'scraped_date', 'wayback_url', 'wayback_time'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ef8d5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14044, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for property_id duplicates\n",
    "df['property_id'].duplicated().sum()\n",
    "\n",
    "# sort by year, quarter descending\n",
    "df = df.sort_values(by=['year', 'quarter'], ascending=False)\n",
    "\n",
    "# drop duplicates but keep first occurrence\n",
    "df = df.drop_duplicates(subset=['property_id'], keep='first')\n",
    "\n",
    "df.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4540522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 14044 entries, 13740 to 19\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   property_id    14044 non-null  int64  \n",
      " 1   rental_price   14044 non-null  float64\n",
      " 2   bedrooms       14043 non-null  Int64  \n",
      " 3   bathrooms      14043 non-null  Int64  \n",
      " 4   car_spaces     14043 non-null  Int64  \n",
      " 5   property_type  14044 non-null  object \n",
      " 6   suburb         14044 non-null  object \n",
      " 7   year           14044 non-null  int64  \n",
      " 8   quarter        14044 non-null  int64  \n",
      " 9   address        14044 non-null  object \n",
      "dtypes: Int64(3), float64(1), int64(3), object(3)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67669da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 14043 entries, 13740 to 19\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   property_id    14043 non-null  int64  \n",
      " 1   rental_price   14043 non-null  float64\n",
      " 2   bedrooms       14043 non-null  Int64  \n",
      " 3   bathrooms      14043 non-null  Int64  \n",
      " 4   car_spaces     14043 non-null  Int64  \n",
      " 5   property_type  14043 non-null  object \n",
      " 6   suburb         14043 non-null  object \n",
      " 7   year           14043 non-null  int64  \n",
      " 8   quarter        14043 non-null  int64  \n",
      " 9   address        14043 non-null  object \n",
      "dtypes: Int64(3), float64(1), int64(3), object(3)\n",
      "memory usage: 1.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14043, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop remaining nulls\n",
    "df = df.dropna()\n",
    "\n",
    "df.info()\n",
    "\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cefdbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to data/processed/domain/wayback_listings.csv\n",
    "df.to_csv(\"../data/processed/domain/wayback_listings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f24ad1",
   "metadata": {},
   "source": [
    "# Fetching Coordinates/ Geocoding the Address of Wayback Listings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211202ed",
   "metadata": {},
   "source": [
    "We need to geocode the address to get the latitude and longitude. Let us first save the listings to `data/raw/missing_coordinates`. This way we know which listings still need to be geocoded. We will be using the Open Route Service Geocode API which has an API request limit of 1000 per key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3089dbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch_0001.csv: 1000 rows\n",
      "Saved batch_0002.csv: 1000 rows\n",
      "Saved batch_0003.csv: 1000 rows\n",
      "Saved batch_0004.csv: 1000 rows\n",
      "Saved batch_0005.csv: 1000 rows\n",
      "Saved batch_0006.csv: 1000 rows\n",
      "Saved batch_0007.csv: 1000 rows\n",
      "Saved batch_0008.csv: 1000 rows\n",
      "Saved batch_0009.csv: 1000 rows\n",
      "Saved batch_0010.csv: 1000 rows\n",
      "Saved batch_0011.csv: 1000 rows\n",
      "Saved batch_0012.csv: 1000 rows\n",
      "Saved batch_0013.csv: 1000 rows\n",
      "Saved batch_0014.csv: 1000 rows\n",
      "Saved batch_0015.csv: 43 rows\n",
      "\n",
      "Total batches created: 15\n",
      "Output directory: ../data/raw/missing_coordinates\n",
      "\n",
      "Created 15 batch files\n"
     ]
    }
   ],
   "source": [
    "# Split the dataframe into batches and save to output directory\n",
    "output_dir = \"../data/raw/missing_coordinates\"\n",
    "batch_size = 1000\n",
    "\n",
    "batch_files = preprocessor.split_into_batches(df[['property_id', 'address']], batch_size, output_dir)\n",
    "print(f\"\\nCreated {len(batch_files)} batch files\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c006e2e9",
   "metadata": {},
   "source": [
    "After setting up the input files, we can now run the script from the project `/` directory `./run_geocode.sh`. This should then create 15 files in `data/processed/coordinates`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20d3b434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting merge process...\n",
      "Input directory: ../data/processed/coordinates\n",
      "File pattern: batch_*.csv\n",
      "------------------------------------------------------------\n",
      "Found 16 files to merge:\n",
      "  - batch_0001_geocoded.csv\n",
      "  - batch_0002_geocoded.csv\n",
      "  - batch_0003_geocoded.csv\n",
      "  - batch_0004_geocoded.csv\n",
      "  - batch_0005_geocoded.csv\n",
      "  - batch_0006_geocoded.csv\n",
      "  - batch_0007_geocoded.csv\n",
      "  - batch_0008_geocoded.csv\n",
      "  - batch_0009_geocoded.csv\n",
      "  - batch_0010_geocoded.csv\n",
      "  - batch_0011_geocoded.csv\n",
      "  - batch_0012_geocoded.csv\n",
      "  - batch_0013_geocoded.csv\n",
      "  - batch_0014_geocoded.csv\n",
      "  - batch_0015_geocoded.csv\n",
      "  - batch_0016_geocoded.csv\n",
      "\n",
      "  Loaded: batch_0001_geocoded.csv (1,000 rows)\n",
      "  Loaded: batch_0002_geocoded.csv (1,000 rows)\n",
      "  Loaded: batch_0003_geocoded.csv (1,000 rows)\n",
      "  Loaded: batch_0004_geocoded.csv (1,000 rows)\n",
      "  Loaded: batch_0005_geocoded.csv (1,000 rows)\n",
      "  Loaded: batch_0006_geocoded.csv (1,000 rows)\n",
      "  Loaded: batch_0007_geocoded.csv (1,000 rows)\n",
      "  Loaded: batch_0008_geocoded.csv (1,000 rows)\n",
      "  Loaded: batch_0009_geocoded.csv (1,000 rows)\n",
      "  Loaded: batch_0010_geocoded.csv (1,000 rows)\n",
      "  Loaded: batch_0011_geocoded.csv (1,000 rows)\n",
      "  Loaded: batch_0012_geocoded.csv (1,000 rows)\n",
      "  Loaded: batch_0013_geocoded.csv (1,000 rows)\n",
      "  Loaded: batch_0014_geocoded.csv (1,000 rows)\n",
      "  Loaded: batch_0015_geocoded.csv (44 rows)\n",
      "  Loaded: batch_0016_geocoded.csv (260 rows)\n",
      "\n",
      "Merging 16 dataframes...\n",
      "============================================================\n",
      "✓ Merge completed successfully!\n",
      "✓ Total rows: 14,304\n",
      "✓ Total columns: 6\n",
      "✓ Column names: ['property_id', 'address', 'longitude', 'latitude', 'coordinates', 'geocode_success']\n",
      "============================================================\n",
      "(13303, 4)\n"
     ]
    }
   ],
   "source": [
    "# read in all the csv in data/processed/coordinates and stack into single dataframe\n",
    "df_coordinates = preprocessor.merge_batches(\"../data/processed/coordinates\", pattern=\"batch_*.csv\",verbose=True)\n",
    "\n",
    "# drop rows where geocode_success is False\n",
    "df_coordinates = df_coordinates[df_coordinates['geocode_success']]\n",
    "\n",
    "# drop the geocode_success column\n",
    "df_coordinates = df_coordinates.drop(columns=['geocode_success'])\n",
    "\n",
    "# drop the address column\n",
    "df_coordinates = df_coordinates.drop(columns=['address'])\n",
    "\n",
    "# fix the order of coordinates\n",
    "# convert longitude and latitude to Point\n",
    "df_coordinates['coordinates'] = df_coordinates.apply(lambda row: Point(row['latitude'], row['longitude']), axis=1)\n",
    "\n",
    "print(df_coordinates.shape)\n",
    "# save to data/processed/coordinates/geocoded_listings.csv\n",
    "df_coordinates.to_csv(\"../data/processed/coordinates/geocoded_wayback_listings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "80558cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_id</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15295193</td>\n",
       "      <td>144.889952</td>\n",
       "      <td>-37.791139</td>\n",
       "      <td>POINT (-37.791139 144.889952)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15624467</td>\n",
       "      <td>144.896622</td>\n",
       "      <td>-37.798680</td>\n",
       "      <td>POINT (-37.79868 144.896622)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15726089</td>\n",
       "      <td>144.884333</td>\n",
       "      <td>-37.791939</td>\n",
       "      <td>POINT (-37.791939 144.884333)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15754757</td>\n",
       "      <td>144.905187</td>\n",
       "      <td>-37.802479</td>\n",
       "      <td>POINT (-37.802479 144.905187)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15802091</td>\n",
       "      <td>144.908234</td>\n",
       "      <td>-37.801644</td>\n",
       "      <td>POINT (-37.801644 144.908234)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14299</th>\n",
       "      <td>13001612</td>\n",
       "      <td>146.146464</td>\n",
       "      <td>-38.209552</td>\n",
       "      <td>POINT (-38.209552 146.146464)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14300</th>\n",
       "      <td>17530473</td>\n",
       "      <td>146.147961</td>\n",
       "      <td>-38.207978</td>\n",
       "      <td>POINT (-38.207978 146.147961)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14301</th>\n",
       "      <td>17597533</td>\n",
       "      <td>146.154994</td>\n",
       "      <td>-38.211812</td>\n",
       "      <td>POINT (-38.211812 146.154994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14302</th>\n",
       "      <td>17618453</td>\n",
       "      <td>146.157027</td>\n",
       "      <td>-38.216646</td>\n",
       "      <td>POINT (-38.216646 146.157027)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14303</th>\n",
       "      <td>17622779</td>\n",
       "      <td>146.160339</td>\n",
       "      <td>-38.208019</td>\n",
       "      <td>POINT (-38.208019 146.160339)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13303 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       property_id   longitude   latitude                    coordinates\n",
       "0         15295193  144.889952 -37.791139  POINT (-37.791139 144.889952)\n",
       "1         15624467  144.896622 -37.798680   POINT (-37.79868 144.896622)\n",
       "2         15726089  144.884333 -37.791939  POINT (-37.791939 144.884333)\n",
       "3         15754757  144.905187 -37.802479  POINT (-37.802479 144.905187)\n",
       "4         15802091  144.908234 -37.801644  POINT (-37.801644 144.908234)\n",
       "...            ...         ...        ...                            ...\n",
       "14299     13001612  146.146464 -38.209552  POINT (-38.209552 146.146464)\n",
       "14300     17530473  146.147961 -38.207978  POINT (-38.207978 146.147961)\n",
       "14301     17597533  146.154994 -38.211812  POINT (-38.211812 146.154994)\n",
       "14302     17618453  146.157027 -38.216646  POINT (-38.216646 146.157027)\n",
       "14303     17622779  146.160339 -38.208019  POINT (-38.208019 146.160339)\n",
       "\n",
       "[13303 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e12f2e",
   "metadata": {},
   "source": [
    "# Combining Live Listings with Wayback Listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "38d4fcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in live listings from data/processed/domain/live_listings.csv\n",
    "live_listings = pd.read_csv(\"../data/processed/domain/live_listings.csv\")\n",
    "\n",
    "live_listings['coordinates'] = live_listings.apply(lambda x: Point(x['latitude'], x['longitude']) if pd.notna(x['latitude']) and pd.notna(x['longitude']) else None, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "629bca29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 13301 entries, 176 to 15280\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   property_id    13301 non-null  int64  \n",
      " 1   rental_price   13301 non-null  float64\n",
      " 2   bedrooms       13301 non-null  int64  \n",
      " 3   bathrooms      13301 non-null  int64  \n",
      " 4   car_spaces     13301 non-null  int64  \n",
      " 5   property_type  13301 non-null  object \n",
      " 6   suburb         13301 non-null  object \n",
      " 7   year           13301 non-null  int64  \n",
      " 8   quarter        13301 non-null  int64  \n",
      " 9   longitude      13301 non-null  float64\n",
      " 10  latitude       13301 non-null  float64\n",
      " 11  coordinates    13301 non-null  object \n",
      "dtypes: float64(3), int64(6), object(3)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# read in wayback listings from data/processed/domain/wayback_listings.csv\n",
    "wayback_listings = pd.read_csv(\"../data/processed/domain/wayback_listings.csv\")\n",
    "\n",
    "# merge wayback_listings with df_coordinates on property_id\n",
    "wayback_listings = wayback_listings.merge(df_coordinates, on='property_id', how='left')\n",
    "\n",
    "# drop the rows where coordinates is None\n",
    "wayback_listings = wayback_listings[wayback_listings['coordinates'].notna()]\n",
    "\n",
    "# drop address column\n",
    "wayback_listings = wayback_listings.drop(columns=['address'])\n",
    "\n",
    "wayback_listings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3080f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack live_listings and wayback_listings summary data\n",
    "live_listings = live_listings[wayback_listings.columns]\n",
    "# concat live_listings and wayback_listings \n",
    "df = pd.concat([live_listings, wayback_listings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "80943fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by year, quarter descending\n",
    "df = df.sort_values(by=['year', 'quarter'], ascending=False)\n",
    "\n",
    "# drop duplicates but keep first occurrence\n",
    "df = df.drop_duplicates(subset=['property_id'], keep='first')\n",
    "\n",
    "# save to data/processed/domain/cleaned_listings.csv\n",
    "df.to_csv(\"../data/processed/domain/cleaned_listings.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f6cdf7",
   "metadata": {},
   "source": [
    "# Isochrones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c406a82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data/processed/poi_features/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b72578",
   "metadata": {},
   "source": [
    "# Stratified Sampling\n",
    "\n",
    "Randomly shuffle and stratify sample the dataframe down to 50% by property_type, suburb, and bedrooms. This helps reduce computational cost while maintaining representative distribution of property characteristics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c74e0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 24,517 rows\n",
      "Sampled size: 13,101 rows\n",
      "Sampling ratio: 53.4%\n",
      "\n",
      "--- Property Type Distribution ---\n",
      "Original:\n",
      "property_type\n",
      "house                      0.256597\n",
      "House                      0.253253\n",
      "apartment / unit / flat    0.195905\n",
      "Apartment / Unit / Flat    0.167680\n",
      "Townhouse                  0.056736\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Sampled:\n",
      "property_type\n",
      "house                      0.251279\n",
      "House                      0.250897\n",
      "apartment / unit / flat    0.190214\n",
      "Apartment / Unit / Flat    0.166094\n",
      "Townhouse                  0.061140\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "--- Bedrooms Distribution ---\n",
      "Original:\n",
      "bedrooms\n",
      "1     0.135946\n",
      "2     0.288983\n",
      "3     0.333442\n",
      "4     0.218746\n",
      "5     0.019660\n",
      "6     0.001999\n",
      "7     0.000571\n",
      "8     0.000367\n",
      "9     0.000245\n",
      "50    0.000041\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Sampled:\n",
      "bedrooms\n",
      "1     0.138005\n",
      "2     0.288909\n",
      "3     0.325319\n",
      "4     0.216472\n",
      "5     0.025571\n",
      "6     0.003511\n",
      "7     0.001069\n",
      "8     0.000611\n",
      "9     0.000458\n",
      "50    0.000076\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xj/ny4zmnqd609bv2rpjzzr11rm0000gn/T/ipykernel_57411/3131207073.py:16: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_sampled = df_shuffled.groupby('strata', group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# First, shuffle the dataframe randomly\n",
    "df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Create stratification groups based on property_type, suburb, and bedrooms\n",
    "df_shuffled['strata'] = (\n",
    "    df_shuffled['property_type'].astype(str) + '_' + \n",
    "    df_shuffled['suburb'].astype(str) + '_' + \n",
    "    df_shuffled['bedrooms'].astype(str)\n",
    ")\n",
    "\n",
    "# Perform stratified sampling to get 50% of the data\n",
    "df_sampled = df_shuffled.groupby('strata', group_keys=False).apply(\n",
    "    lambda x: x.sample(frac=0.5, random_state=42) if len(x) > 1 else x\n",
    ")\n",
    "\n",
    "# Drop the temporary strata column\n",
    "df_sampled = df_sampled.drop(columns=['strata'])\n",
    "\n",
    "# Reset index\n",
    "df_sampled = df_sampled.reset_index(drop=True)\n",
    "\n",
    "print(f\"Original size: {len(df_shuffled):,} rows\")\n",
    "print(f\"Sampled size: {len(df_sampled):,} rows\")\n",
    "print(f\"Sampling ratio: {len(df_sampled) / len(df_shuffled):.1%}\")\n",
    "\n",
    "# Verify distribution is maintained\n",
    "print(\"\\n--- Property Type Distribution ---\")\n",
    "print(\"Original:\")\n",
    "print(df_shuffled['property_type'].value_counts(normalize=True).head())\n",
    "print(\"\\nSampled:\")\n",
    "print(df_sampled['property_type'].value_counts(normalize=True).head())\n",
    "\n",
    "print(\"\\n--- Bedrooms Distribution ---\")\n",
    "print(\"Original:\")\n",
    "print(df_shuffled['bedrooms'].value_counts(normalize=True).sort_index())\n",
    "print(\"\\nSampled:\")\n",
    "print(df_sampled['bedrooms'].value_counts(normalize=True).sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b659fc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved stratified sampled data to: data/processed/domain/cleaned_listings_sampled.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the sampled dataframe\n",
    "df_sampled.to_csv(\"../data/processed/domain/cleaned_listings_sampled.csv\", index=False)\n",
    "print(\"\\n✓ Saved stratified sampled data to: data/processed/domain/cleaned_listings_sampled.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ecd85b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final sampled dataset:\n",
      "Shape: (13101, 12)\n",
      "\n",
      "Unique suburbs: 368\n",
      "Unique property types: 24\n",
      "\n",
      "Top 10 suburbs by count:\n",
      "suburb\n",
      "melbourne                         616\n",
      "tarneit                           196\n",
      "southbank                         191\n",
      "werribee-hoppers crossing         189\n",
      "south yarra                       157\n",
      "north melbourne-west melbourne    155\n",
      "truganina                         154\n",
      "shepparton                        139\n",
      "st kilda                          131\n",
      "glen waverley-mulgrave            128\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display summary statistics\n",
    "print(\"Final sampled dataset:\")\n",
    "print(f\"Shape: {df_sampled.shape}\")\n",
    "print(f\"\\nUnique suburbs: {df_sampled['suburb'].nunique()}\")\n",
    "print(f\"Unique property types: {df_sampled['property_type'].nunique()}\")\n",
    "print(f\"\\nTop 10 suburbs by count:\")\n",
    "print(df_sampled['suburb'].value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cd8b1b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13101 entries, 0 to 13100\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   property_id    13101 non-null  float64\n",
      " 1   rental_price   13101 non-null  float64\n",
      " 2   bedrooms       13101 non-null  int64  \n",
      " 3   bathrooms      13101 non-null  int64  \n",
      " 4   car_spaces     13101 non-null  int64  \n",
      " 5   property_type  13101 non-null  object \n",
      " 6   suburb         13101 non-null  object \n",
      " 7   year           13101 non-null  int64  \n",
      " 8   quarter        13101 non-null  int64  \n",
      " 9   longitude      13101 non-null  float64\n",
      " 10  latitude       13101 non-null  float64\n",
      " 11  coordinates    13101 non-null  object \n",
      "dtypes: float64(4), int64(5), object(3)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_sampled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "502e2cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6499 entries, 0 to 13051\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   property_id    6499 non-null   float64\n",
      " 1   rental_price   6499 non-null   float64\n",
      " 2   bedrooms       6499 non-null   int64  \n",
      " 3   bathrooms      6499 non-null   int64  \n",
      " 4   car_spaces     6499 non-null   int64  \n",
      " 5   property_type  6499 non-null   object \n",
      " 6   suburb         6499 non-null   object \n",
      " 7   year           6499 non-null   int64  \n",
      " 8   quarter        6499 non-null   int64  \n",
      " 9   longitude      6499 non-null   float64\n",
      " 10  latitude       6499 non-null   float64\n",
      " 11  coordinates    6499 non-null   object \n",
      "dtypes: float64(4), int64(5), object(3)\n",
      "memory usage: 660.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# select the rows of df_sampled where property_id is in wayback_listings['property_id']\n",
    "df_sampled_wayback = df_sampled[df_sampled['property_id'].isin(wayback_listings['property_id'])]\n",
    "\n",
    "df_sampled_wayback.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "afb7a164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch_0001.csv: 500 rows\n",
      "Saved batch_0002.csv: 500 rows\n",
      "Saved batch_0003.csv: 500 rows\n",
      "Saved batch_0004.csv: 500 rows\n",
      "Saved batch_0005.csv: 500 rows\n",
      "Saved batch_0006.csv: 500 rows\n",
      "Saved batch_0007.csv: 500 rows\n",
      "Saved batch_0008.csv: 500 rows\n",
      "Saved batch_0009.csv: 500 rows\n",
      "Saved batch_0010.csv: 500 rows\n",
      "Saved batch_0011.csv: 500 rows\n",
      "Saved batch_0012.csv: 500 rows\n",
      "Saved batch_0013.csv: 499 rows\n",
      "\n",
      "Total batches created: 13\n",
      "Output directory: ../data/raw/missing_isochrones_wayback/driving\n",
      "Saved batch_0001.csv: 500 rows\n",
      "Saved batch_0002.csv: 500 rows\n",
      "Saved batch_0003.csv: 500 rows\n",
      "Saved batch_0004.csv: 500 rows\n",
      "Saved batch_0005.csv: 500 rows\n",
      "Saved batch_0006.csv: 500 rows\n",
      "Saved batch_0007.csv: 500 rows\n",
      "Saved batch_0008.csv: 500 rows\n",
      "Saved batch_0009.csv: 500 rows\n",
      "Saved batch_0010.csv: 500 rows\n",
      "Saved batch_0011.csv: 500 rows\n",
      "Saved batch_0012.csv: 500 rows\n",
      "Saved batch_0013.csv: 499 rows\n",
      "\n",
      "Total batches created: 13\n",
      "Output directory: ../data/raw/missing_isochrones_wayback/walking\n",
      "Saved batch_0001.csv: 500 rows\n",
      "Saved batch_0002.csv: 500 rows\n",
      "Saved batch_0003.csv: 500 rows\n",
      "Saved batch_0004.csv: 500 rows\n",
      "Saved batch_0005.csv: 500 rows\n",
      "Saved batch_0006.csv: 500 rows\n",
      "Saved batch_0007.csv: 500 rows\n",
      "Saved batch_0008.csv: 500 rows\n",
      "Saved batch_0009.csv: 500 rows\n",
      "Saved batch_0010.csv: 500 rows\n",
      "Saved batch_0011.csv: 500 rows\n",
      "Saved batch_0012.csv: 500 rows\n",
      "Saved batch_0013.csv: 499 rows\n",
      "\n",
      "Total batches created: 13\n",
      "Output directory: ../data/raw/missing_poi_wayback\n",
      "Saved batch_0001.csv: 500 rows\n",
      "Saved batch_0002.csv: 500 rows\n",
      "Saved batch_0003.csv: 500 rows\n",
      "Saved batch_0004.csv: 500 rows\n",
      "Saved batch_0005.csv: 500 rows\n",
      "Saved batch_0006.csv: 500 rows\n",
      "Saved batch_0007.csv: 500 rows\n",
      "Saved batch_0008.csv: 500 rows\n",
      "Saved batch_0009.csv: 500 rows\n",
      "Saved batch_0010.csv: 500 rows\n",
      "Saved batch_0011.csv: 500 rows\n",
      "Saved batch_0012.csv: 500 rows\n",
      "Saved batch_0013.csv: 499 rows\n",
      "\n",
      "Total batches created: 13\n",
      "Output directory: ../data/raw/missing_routes_wayback\n"
     ]
    }
   ],
   "source": [
    "batch_size = 500\n",
    "for output_dir in [\"../data/raw/missing_isochrones_wayback/driving\", \"../data/raw/missing_isochrones_wayback/walking\", \"../data/raw/missing_poi_wayback\", \"../data/raw/missing_routes_wayback\"]:\n",
    "    preprocessor.split_into_batches(df_sampled_wayback[['property_id', 'coordinates']], batch_size, output_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

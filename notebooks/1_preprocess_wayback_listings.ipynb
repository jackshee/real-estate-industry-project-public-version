{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8470fe2",
   "metadata": {},
   "source": [
    "This notebook performs basic preprocessing for the wayback scraped listings. It also sets up intermediate files required calling GeoCode API via Open Route Service. The results from running this notebook are saved to `data/processed/domain/wayback_listings.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8810b826",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "388029be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50dd0157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenRouteService client initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "from utils.preprocess import PreprocessUtils\n",
    "from utils.geo import GeoUtils\n",
    "\n",
    "# Initialize the preprocessor\n",
    "preprocessor = PreprocessUtils()\n",
    "\n",
    "# Initialize the geo utils\n",
    "geo_utils = GeoUtils()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff330793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14 files to process:\n",
      "  - rental_listings_2022_03.csv\n",
      "  - rental_listings_2022_06.csv\n",
      "  - rental_listings_2022_09.csv\n",
      "  - rental_listings_2022_12.csv\n",
      "  - rental_listings_2023_03.csv\n",
      "  - rental_listings_2023_06.csv\n",
      "  - rental_listings_2023_09.csv\n",
      "  - rental_listings_2023_12.csv\n",
      "  - rental_listings_2024_03.csv\n",
      "  - rental_listings_2024_06.csv\n",
      "  - rental_listings_2024_09.csv\n",
      "  - rental_listings_2024_12.csv\n",
      "  - rental_listings_2025_03.csv\n",
      "  - rental_listings_2025_06.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the domain folder\n",
    "domain_path = \"../data/raw/domain\"\n",
    "\n",
    "# Get all CSV files except rental_listings_2025_09.csv\n",
    "csv_files = glob.glob(os.path.join(domain_path, \"rental_listings_*.csv\"))\n",
    "csv_files = [f for f in csv_files if \"rental_listings_2025_09.csv\" not in f]\n",
    "\n",
    "print(f\"Found {len(csv_files)} files to process:\")\n",
    "for f in sorted(csv_files):\n",
    "    print(f\"  - {os.path.basename(f)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf84301f",
   "metadata": {},
   "source": [
    "Here we make the assumption that the listings on wayback have an `updated_dated` that is equal to the `scraped_date`. Because we scraped a random day with an existing snapshot for each suburb in each quarter going back to 2022 Q1, we essentially have more rental price data for listings last updated in the \"past\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9ec82f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded rental_listings_2022_03.csv: 20 rows, Year=2022, Quarter=1\n",
      "Loaded rental_listings_2022_06.csv: 3047 rows, Year=2022, Quarter=2\n",
      "Loaded rental_listings_2022_09.csv: 710 rows, Year=2022, Quarter=3\n",
      "Loaded rental_listings_2022_12.csv: 23 rows, Year=2022, Quarter=4\n",
      "Loaded rental_listings_2023_03.csv: 123 rows, Year=2023, Quarter=1\n",
      "Loaded rental_listings_2023_06.csv: 98 rows, Year=2023, Quarter=2\n",
      "Loaded rental_listings_2023_09.csv: 20 rows, Year=2023, Quarter=3\n",
      "Loaded rental_listings_2023_12.csv: 179 rows, Year=2023, Quarter=4\n",
      "Loaded rental_listings_2024_03.csv: 1372 rows, Year=2024, Quarter=1\n",
      "Loaded rental_listings_2024_06.csv: 1786 rows, Year=2024, Quarter=2\n",
      "Loaded rental_listings_2024_09.csv: 1460 rows, Year=2024, Quarter=3\n",
      "Loaded rental_listings_2024_12.csv: 1562 rows, Year=2024, Quarter=4\n",
      "Loaded rental_listings_2025_03.csv: 3340 rows, Year=2025, Quarter=1\n",
      "Loaded rental_listings_2025_06.csv: 3382 rows, Year=2025, Quarter=2\n",
      "\n",
      "Total dataframes loaded: 14\n"
     ]
    }
   ],
   "source": [
    "# Read all CSV files and add year and quarter columns\n",
    "dataframes = []\n",
    "\n",
    "for csv_file in sorted(csv_files):\n",
    "    # Extract filename without extension\n",
    "    filename = os.path.basename(csv_file)\n",
    "    # Parse filename: rental_listings_YYYY_MM.csv\n",
    "    parts = filename.replace('.csv', '').split('_')\n",
    "    year = parts[2]\n",
    "    month = parts[3]\n",
    "    \n",
    "    # Map month to quarter\n",
    "    month_to_quarter = {\n",
    "        '03': 1,\n",
    "        '06': 2,\n",
    "        '09': 3,\n",
    "        '12': 4\n",
    "    }\n",
    "    quarter = month_to_quarter.get(month, 'Unknown')\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Add year and quarter columns\n",
    "    df['year'] = int(year)\n",
    "    df['quarter'] = quarter\n",
    "    \n",
    "    dataframes.append(df)\n",
    "    print(f\"Loaded {filename}: {len(df)} rows, Year={year}, Quarter={quarter}\")\n",
    "\n",
    "print(f\"\\nTotal dataframes loaded: {len(dataframes)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b875fa0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17122 entries, 0 to 17121\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   property_id        17122 non-null  int64  \n",
      " 1   url                17122 non-null  object \n",
      " 2   rental_price       17122 non-null  object \n",
      " 3   bedrooms           16994 non-null  float64\n",
      " 4   bathrooms          17067 non-null  float64\n",
      " 5   car_spaces         15120 non-null  float64\n",
      " 6   property_type      17122 non-null  object \n",
      " 7   land_area          17122 non-null  float64\n",
      " 8   property_features  17122 non-null  object \n",
      " 9   suburb             17122 non-null  object \n",
      " 10  postcode           17122 non-null  int64  \n",
      " 11  scraped_date       17122 non-null  object \n",
      " 12  wayback_url        17122 non-null  object \n",
      " 13  wayback_time       17122 non-null  int64  \n",
      " 14  year               17122 non-null  int64  \n",
      " 15  quarter            17122 non-null  int64  \n",
      "dtypes: float64(4), int64(5), object(7)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Stack all dataframes together\n",
    "df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7eb9469b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map the suburbs to standardized names (used by DFFH dataset)\n",
    "df['suburb'] = preprocessor.map_suburb(df['suburb'])\n",
    "\n",
    "# Remove the suburbs that have count less than 10\n",
    "suburb_counts = df['suburb'].value_counts()\n",
    "valid_suburbs = suburb_counts[suburb_counts > 10].index\n",
    "df = df[df['suburb'].isin(valid_suburbs)]\n",
    "\n",
    "df['suburb'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac32bd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop land_area column\n",
    "df = df.drop(columns=['land_area'])\n",
    "\n",
    "# convert bedrooms, bathrooms, car_spaces to Int64\n",
    "df['bedrooms'] = df['bedrooms'].astype('Int64')\n",
    "df['bathrooms'] = df['bathrooms'].astype('Int64')\n",
    "df['car_spaces'] = df['car_spaces'].astype('Int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9e24131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before imputation:\n",
      "bedrooms       108\n",
      "bathrooms       42\n",
      "car_spaces    1767\n",
      "dtype: int64\n",
      "Property type: Apartment / Unit / Flat, bedrooms imputed with 2\n",
      "Property type: Townhouse, bedrooms imputed with 3\n",
      "Property type: House, bedrooms imputed with 3\n",
      "Property type: Studio, bedrooms imputed with 1\n",
      "Property type: Duplex, bedrooms imputed with 2\n",
      "Property type: Vacant land, bedrooms imputed with 4\n",
      "Property type: Farm, bedrooms imputed with <NA>\n",
      "Property type: Apartment / Unit / Flat, bathrooms imputed with 1\n",
      "Property type: Townhouse, bathrooms imputed with 2\n",
      "Property type: House, bathrooms imputed with 2\n",
      "Property type: Studio, bathrooms imputed with 1\n",
      "Property type: Vacant land, bathrooms imputed with 2\n",
      "Property type: Farm, bathrooms imputed with <NA>\n",
      "Property type: Apartment / Unit / Flat, car_spaces imputed with 1\n",
      "Property type: Townhouse, car_spaces imputed with 2\n",
      "Property type: House, car_spaces imputed with 2\n",
      "Property type: Studio, car_spaces imputed with 1\n",
      "Property type: New Apartments / Off the Plan, car_spaces imputed with 1\n",
      "Property type: Duplex, car_spaces imputed with 1\n",
      "Property type: Vacant land, car_spaces imputed with 2\n",
      "Property type: Acreage / Semi-Rural, car_spaces imputed with 4\n",
      "Property type: Villa, car_spaces imputed with 1\n",
      "Property type: Unknown, car_spaces imputed with 1\n",
      "Property type: Terrace, car_spaces imputed with 2\n",
      "Property type: New House & Land, car_spaces imputed with 2\n",
      "Property type: Farm, car_spaces imputed with <NA>\n",
      "\n",
      "After imputation:\n",
      "bedrooms      1\n",
      "bathrooms     1\n",
      "car_spaces    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# impute bedrooms, bathrooms, car_spaces with preprocessor\n",
    "# handle missing values by imputing by mode grouped by property_type\n",
    "print(\"Before imputation:\")\n",
    "print(df[['bedrooms', 'bathrooms', 'car_spaces']].isnull().sum())\n",
    "\n",
    "# Impute bedrooms using property_type mode\n",
    "df['bedrooms'] = preprocessor.impute_by_property_type_mode(df, 'bedrooms')\n",
    "\n",
    "# Impute bathrooms using property_type mode\n",
    "df['bathrooms'] = preprocessor.impute_by_property_type_mode(df, 'bathrooms')\n",
    "\n",
    "# Impute car_spaces using property_type mode\n",
    "df['car_spaces'] = preprocessor.impute_by_property_type_mode(df, 'car_spaces')\n",
    "\n",
    "print(\"\\nAfter imputation:\")\n",
    "print(df[['bedrooms', 'bathrooms', 'car_spaces']].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f1b8d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with unknown price frequencies: 351\n"
     ]
    }
   ],
   "source": [
    "# Extract weekly rent from rental_price column\n",
    "df['rental_price'] = preprocessor.extract_rental_price(df['rental_price'])\n",
    "\n",
    "# Check how many rows have unknown frequencies (NaN in weekly_rent)\n",
    "unknown_count = df['rental_price'].isna().sum()\n",
    "print(f\"Rows with unknown price frequencies: {unknown_count}\")\n",
    "\n",
    "# Drop rows with unknown frequencies\n",
    "df = df[df['rental_price'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9fd8e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_id</th>\n",
       "      <th>rental_price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>car_spaces</th>\n",
       "      <th>property_type</th>\n",
       "      <th>suburb</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15295193</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Apartment / Unit / Flat</td>\n",
       "      <td>footscray</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>51 Gordon Street, Footscray, VIC 3011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15624467</td>\n",
       "      <td>385.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Townhouse</td>\n",
       "      <td>footscray</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>Cirque Drive, Footscray, VIC 3011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15726089</td>\n",
       "      <td>470.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>House</td>\n",
       "      <td>footscray</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>10 Stanlake Street, Footscray, VIC 3011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15754757</td>\n",
       "      <td>410.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Apartment / Unit / Flat</td>\n",
       "      <td>footscray</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>42 Whitehall Street, Footscray, VIC 3011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15802091</td>\n",
       "      <td>650.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>House</td>\n",
       "      <td>footscray</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>2 Saltriver Place, Footscray, VIC 3011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17113</th>\n",
       "      <td>13001612</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>House</td>\n",
       "      <td>trafalgar</td>\n",
       "      <td>2025</td>\n",
       "      <td>2</td>\n",
       "      <td>1c Dodemaides, Trafalgar, VIC 3824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17115</th>\n",
       "      <td>17530473</td>\n",
       "      <td>340.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Studio</td>\n",
       "      <td>trafalgar</td>\n",
       "      <td>2025</td>\n",
       "      <td>2</td>\n",
       "      <td>26a Waterloo Road, Trafalgar, VIC 3824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17116</th>\n",
       "      <td>17597533</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>House</td>\n",
       "      <td>trafalgar</td>\n",
       "      <td>2025</td>\n",
       "      <td>2</td>\n",
       "      <td>Princes Way, Trafalgar, VIC 3824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17120</th>\n",
       "      <td>17618453</td>\n",
       "      <td>550.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>House</td>\n",
       "      <td>trafalgar</td>\n",
       "      <td>2025</td>\n",
       "      <td>2</td>\n",
       "      <td>Cross Street, Trafalgar, VIC 3824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17121</th>\n",
       "      <td>17622779</td>\n",
       "      <td>330.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Apartment / Unit / Flat</td>\n",
       "      <td>trafalgar</td>\n",
       "      <td>2025</td>\n",
       "      <td>2</td>\n",
       "      <td>Brown Street, Trafalgar, VIC 3824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15260 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       property_id  rental_price  bedrooms  bathrooms  car_spaces  \\\n",
       "0         15295193         240.0         1          1           1   \n",
       "1         15624467         385.0         2          1           1   \n",
       "2         15726089         470.0         2          1           1   \n",
       "3         15754757         410.0         2          1           1   \n",
       "4         15802091         650.0         3          2           2   \n",
       "...            ...           ...       ...        ...         ...   \n",
       "17113     13001612          70.0         1          1           3   \n",
       "17115     17530473         340.0         1          1           2   \n",
       "17116     17597533         500.0         3          1           2   \n",
       "17120     17618453         550.0         3          2           2   \n",
       "17121     17622779         330.0         1          1           1   \n",
       "\n",
       "                 property_type     suburb  year  quarter  \\\n",
       "0      Apartment / Unit / Flat  footscray  2022        1   \n",
       "1                    Townhouse  footscray  2022        1   \n",
       "2                        House  footscray  2022        1   \n",
       "3      Apartment / Unit / Flat  footscray  2022        1   \n",
       "4                        House  footscray  2022        1   \n",
       "...                        ...        ...   ...      ...   \n",
       "17113                    House  trafalgar  2025        2   \n",
       "17115                   Studio  trafalgar  2025        2   \n",
       "17116                    House  trafalgar  2025        2   \n",
       "17120                    House  trafalgar  2025        2   \n",
       "17121  Apartment / Unit / Flat  trafalgar  2025        2   \n",
       "\n",
       "                                        address  \n",
       "0         51 Gordon Street, Footscray, VIC 3011  \n",
       "1             Cirque Drive, Footscray, VIC 3011  \n",
       "2       10 Stanlake Street, Footscray, VIC 3011  \n",
       "3      42 Whitehall Street, Footscray, VIC 3011  \n",
       "4        2 Saltriver Place, Footscray, VIC 3011  \n",
       "...                                         ...  \n",
       "17113        1c Dodemaides, Trafalgar, VIC 3824  \n",
       "17115    26a Waterloo Road, Trafalgar, VIC 3824  \n",
       "17116          Princes Way, Trafalgar, VIC 3824  \n",
       "17120         Cross Street, Trafalgar, VIC 3824  \n",
       "17121         Brown Street, Trafalgar, VIC 3824  \n",
       "\n",
       "[15260 rows x 10 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract address from url since we don't have the address in the summary listing data\n",
    "df['address'] = df['url'].apply(geo_utils.extract_address_from_url)\n",
    "\n",
    "# drop url column\n",
    "df = df.drop(columns=['url', 'property_features', 'postcode', 'scraped_date', 'wayback_url', 'wayback_time'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ef8d5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14044, 10)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for property_id duplicates\n",
    "df['property_id'].duplicated().sum()\n",
    "\n",
    "# sort by year, quarter descending\n",
    "df = df.sort_values(by=['year', 'quarter'], ascending=False)\n",
    "\n",
    "# drop duplicates but keep first occurrence\n",
    "df = df.drop_duplicates(subset=['property_id'], keep='first')\n",
    "\n",
    "df.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c4540522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 14044 entries, 13740 to 19\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   property_id    14044 non-null  int64  \n",
      " 1   rental_price   14044 non-null  float64\n",
      " 2   bedrooms       14043 non-null  Int64  \n",
      " 3   bathrooms      14043 non-null  Int64  \n",
      " 4   car_spaces     14043 non-null  Int64  \n",
      " 5   property_type  14044 non-null  object \n",
      " 6   suburb         14044 non-null  object \n",
      " 7   year           14044 non-null  int64  \n",
      " 8   quarter        14044 non-null  int64  \n",
      " 9   address        14044 non-null  object \n",
      "dtypes: Int64(3), float64(1), int64(3), object(3)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "67669da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 14043 entries, 13740 to 19\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   property_id    14043 non-null  int64  \n",
      " 1   rental_price   14043 non-null  float64\n",
      " 2   bedrooms       14043 non-null  Int64  \n",
      " 3   bathrooms      14043 non-null  Int64  \n",
      " 4   car_spaces     14043 non-null  Int64  \n",
      " 5   property_type  14043 non-null  object \n",
      " 6   suburb         14043 non-null  object \n",
      " 7   year           14043 non-null  int64  \n",
      " 8   quarter        14043 non-null  int64  \n",
      " 9   address        14043 non-null  object \n",
      "dtypes: Int64(3), float64(1), int64(3), object(3)\n",
      "memory usage: 1.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14043, 10)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop remaining nulls\n",
    "df = df.dropna()\n",
    "\n",
    "df.info()\n",
    "\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1cefdbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to data/processed/domain/wayback_listings.csv\n",
    "df.to_csv(\"../data/processed/domain/wayback_listings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f24ad1",
   "metadata": {},
   "source": [
    "# Fetching Coordinates/ Geocoding the Address of Wayback Listings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211202ed",
   "metadata": {},
   "source": [
    "We need to geocode the address to get the latitude and longitude. Let us first save the listings to `data/raw/missing_coordinates`. This way we know which listings still need to be geocoded. We will be using the Open Route Service Geocode API which has an API request limit of 1000 per key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3089dbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch_0001.csv: 1000 rows\n",
      "Saved batch_0002.csv: 1000 rows\n",
      "Saved batch_0003.csv: 1000 rows\n",
      "Saved batch_0004.csv: 1000 rows\n",
      "Saved batch_0005.csv: 1000 rows\n",
      "Saved batch_0006.csv: 1000 rows\n",
      "Saved batch_0007.csv: 1000 rows\n",
      "Saved batch_0008.csv: 1000 rows\n",
      "Saved batch_0009.csv: 1000 rows\n",
      "Saved batch_0010.csv: 1000 rows\n",
      "Saved batch_0011.csv: 1000 rows\n",
      "Saved batch_0012.csv: 1000 rows\n",
      "Saved batch_0013.csv: 1000 rows\n",
      "Saved batch_0014.csv: 1000 rows\n",
      "Saved batch_0015.csv: 44 rows\n",
      "\n",
      "Total batches created: 15\n",
      "Output directory: ../data/raw/missing_coordinates\n",
      "\n",
      "Created 15 batch files\n"
     ]
    }
   ],
   "source": [
    "# Split the dataframe into batches and save to output directory\n",
    "output_dir = \"../data/raw/missing_coordinates\"\n",
    "batch_size = 1000\n",
    "\n",
    "batch_files = preprocessor.split_into_batches(df[['property_id', 'address']], batch_size, output_dir)\n",
    "print(f\"\\nCreated {len(batch_files)} batch files\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c006e2e9",
   "metadata": {},
   "source": [
    "After setting up the input files, we can now run the script from the project `/` directory `./run_geocode.sh`. This should then create 15 files in `data/processed/coordinates`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e12f2e",
   "metadata": {},
   "source": [
    "# Combining Live Listings with Wayback Listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "38d4fcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in live listings from data/processed/domain/live_listings.csv\n",
    "live_listings = pd.read_csv(\"../data/processed/domain/live_listings.csv\")\n",
    "\n",
    "# read in wayback listings from data/processed/domain/wayback_listings.csv\n",
    "wayback_listings = pd.read_csv(\"../data/processed/domain/wayback_listings.csv\")\n",
    "\n",
    "# stack live_listings[['property_id', 'suburb', 'property_type', 'bedrooms']] and wayback_listings[['property_id', 'suburb', 'property_type', 'bedrooms']]\n",
    "live_listings = live_listings[['property_id', 'suburb', 'property_type', 'bedrooms', 'year', 'quarter']]\n",
    "wayback_listings = wayback_listings[['property_id', 'suburb', 'property_type', 'bedrooms', 'year', 'quarter']]\n",
    "\n",
    "# concat live_listings and wayback_listings \n",
    "df = pd.concat([live_listings, wayback_listings])\n",
    "\n",
    "# convert property_id to int\n",
    "df['property_id'] = df['property_id'].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "80943fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by year, quarter descending\n",
    "df = df.sort_values(by=['year', 'quarter'], ascending=False)\n",
    "\n",
    "# drop duplicates but keep first occurrence\n",
    "df = df.drop_duplicates(subset=['property_id'], keep='first')\n",
    "\n",
    "# save to data/processed/domain/cleaned_listings.csv\n",
    "df.to_csv(\"../data/processed/domain/cleaned_listings.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b72578",
   "metadata": {},
   "source": [
    "# Stratified Sampling\n",
    "\n",
    "Randomly shuffle and stratify sample the dataframe down to 50% by property_type, suburb, and bedrooms. This helps reduce computational cost while maintaining representative distribution of property characteristics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0c74e0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 26,460 rows\n",
      "Sampled size: 14,065 rows\n",
      "Sampling ratio: 53.2%\n",
      "\n",
      "--- Property Type Distribution ---\n",
      "Original:\n",
      "property_type\n",
      "House                      0.275813\n",
      "house                      0.237642\n",
      "apartment / unit / flat    0.181519\n",
      "Apartment / Unit / Flat    0.178193\n",
      "Townhouse                  0.061224\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Sampled:\n",
      "property_type\n",
      "House                      0.271809\n",
      "house                      0.233914\n",
      "apartment / unit / flat    0.177177\n",
      "Apartment / Unit / Flat    0.175258\n",
      "Townhouse                  0.065482\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "--- Bedrooms Distribution ---\n",
      "Original:\n",
      "bedrooms\n",
      "1     0.133787\n",
      "2     0.287415\n",
      "3     0.338473\n",
      "4     0.217347\n",
      "5     0.019803\n",
      "6     0.002041\n",
      "7     0.000529\n",
      "8     0.000340\n",
      "9     0.000227\n",
      "50    0.000038\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Sampled:\n",
      "bedrooms\n",
      "1     0.135869\n",
      "2     0.287096\n",
      "3     0.329968\n",
      "4     0.215997\n",
      "5     0.025382\n",
      "6     0.003626\n",
      "7     0.000995\n",
      "8     0.000569\n",
      "9     0.000427\n",
      "50    0.000071\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xj/ny4zmnqd609bv2rpjzzr11rm0000gn/T/ipykernel_73766/3131207073.py:16: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_sampled = df_shuffled.groupby('strata', group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# First, shuffle the dataframe randomly\n",
    "df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Create stratification groups based on property_type, suburb, and bedrooms\n",
    "df_shuffled['strata'] = (\n",
    "    df_shuffled['property_type'].astype(str) + '_' + \n",
    "    df_shuffled['suburb'].astype(str) + '_' + \n",
    "    df_shuffled['bedrooms'].astype(str)\n",
    ")\n",
    "\n",
    "# Perform stratified sampling to get 50% of the data\n",
    "df_sampled = df_shuffled.groupby('strata', group_keys=False).apply(\n",
    "    lambda x: x.sample(frac=0.5, random_state=42) if len(x) > 1 else x\n",
    ")\n",
    "\n",
    "# Drop the temporary strata column\n",
    "df_sampled = df_sampled.drop(columns=['strata'])\n",
    "\n",
    "# Reset index\n",
    "df_sampled = df_sampled.reset_index(drop=True)\n",
    "\n",
    "print(f\"Original size: {len(df_shuffled):,} rows\")\n",
    "print(f\"Sampled size: {len(df_sampled):,} rows\")\n",
    "print(f\"Sampling ratio: {len(df_sampled) / len(df_shuffled):.1%}\")\n",
    "\n",
    "# Verify distribution is maintained\n",
    "print(\"\\n--- Property Type Distribution ---\")\n",
    "print(\"Original:\")\n",
    "print(df_shuffled['property_type'].value_counts(normalize=True).head())\n",
    "print(\"\\nSampled:\")\n",
    "print(df_sampled['property_type'].value_counts(normalize=True).head())\n",
    "\n",
    "print(\"\\n--- Bedrooms Distribution ---\")\n",
    "print(\"Original:\")\n",
    "print(df_shuffled['bedrooms'].value_counts(normalize=True).sort_index())\n",
    "print(\"\\nSampled:\")\n",
    "print(df_sampled['bedrooms'].value_counts(normalize=True).sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b659fc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved stratified sampled data to: data/processed/domain/cleaned_listings_sampled.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the sampled dataframe\n",
    "df_sampled.to_csv(\"../data/processed/domain/cleaned_listings_sampled.csv\", index=False)\n",
    "print(\"\\n✓ Saved stratified sampled data to: data/processed/domain/cleaned_listings_sampled.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ecd85b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final sampled dataset:\n",
      "Shape: (14065, 6)\n",
      "\n",
      "Unique suburbs: 371\n",
      "Unique property types: 24\n",
      "\n",
      "Top 10 suburbs by count:\n",
      "suburb\n",
      "melbourne                         631\n",
      "tarneit                           199\n",
      "werribee-hoppers crossing         195\n",
      "southbank                         191\n",
      "south yarra                       165\n",
      "shepparton                        163\n",
      "north melbourne-west melbourne    163\n",
      "truganina                         155\n",
      "st kilda                          136\n",
      "clayton                           132\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display summary statistics\n",
    "print(\"Final sampled dataset:\")\n",
    "print(f\"Shape: {df_sampled.shape}\")\n",
    "print(f\"\\nUnique suburbs: {df_sampled['suburb'].nunique()}\")\n",
    "print(f\"Unique property types: {df_sampled['property_type'].nunique()}\")\n",
    "print(f\"\\nTop 10 suburbs by count:\")\n",
    "print(df_sampled['suburb'].value_counts().head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5460dfe3",
   "metadata": {},
   "source": [
    "## Downloading the Data\n",
    "\n",
    "Begin with downloading the provided historic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f895fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from urllib.request import urlretrieve\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b93113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_folder(output_dir):\n",
    "    \"\"\"\n",
    "    Create folders for each stage of the ETL pipeline\n",
    "    :param output_dir: The base directory where the folders will be created\n",
    "    \"\"\"\n",
    "    # set output directory\n",
    "    import os\n",
    "    \n",
    "    # check if data directory exists, if not create it\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # create folders for each stage of the ETL pipeline\n",
    "    for stage in ['landing', 'raw', 'curated', 'analysis']:\n",
    "        stage_path = os.path.join(output_dir, stage)\n",
    "        if not os.path.exists(stage_path):\n",
    "            os.makedirs(stage_path) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9bea358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, output_path, file_type):\n",
    "    \"\"\"\n",
    "    Download a file from a URL to a specified output path\n",
    "    :param url: The URL of the file to download\n",
    "    :param output_path: The local path where the file will be saved\n",
    "    :param file_type: The file extension/type (e.g., 'csv', 'json', 'xlsx')\n",
    "    \"\"\"\n",
    "    # generate output file path\n",
    "    output_file_path = f\"{output_path}.{file_type}\"\n",
    "\n",
    "    # check if output file already exists\n",
    "    if not os.path.exists(output_file_path):\n",
    "        os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "        # download the file from the URL and save it to the output file path\n",
    "        urlretrieve(url, output_file_path)\n",
    "        print(f\"File downloaded and saved to {output_file_path}\")\n",
    "    else:\n",
    "        print(f\"File already exists at {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "135eb47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data directories\n",
    "create_data_folder('../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdbe6ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "import os, zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b9d01c",
   "metadata": {},
   "source": [
    "**Download moving annual rent by suburb from ABS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d972787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create rent_by_suburb directory\n",
    "directory = '../data/landing/rent/rent_by_suburb'\n",
    "\n",
    "# URL\n",
    "URL_TEMPLATE = \"https://www.dffh.vic.gov.au/moving-annual-rents-suburb-march-quarter-2023-excel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba3f57f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved to ../data/landing/rent/rent_by_suburb.xlsx\n"
     ]
    }
   ],
   "source": [
    "download_file(URL_TEMPLATE, directory, 'xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa08302",
   "metadata": {},
   "source": [
    "**Download Public Transport Lines and Stops from VIC Gov open data (public transport)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87544a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create public_transport_stops directory\n",
    "directory = '../data/landing/ptv/public_transport_stops'\n",
    "\n",
    "# URL\n",
    "URL_TEMPLATE = \"https://opendata.transport.vic.gov.au/dataset/6d36dfd9-8693-4552-8a03-05eb29a391fd/resource/afa7b823-0c8b-47a1-bc40-ada565f684c7/download/public_transport_stops.geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8767b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved to ../data/landing/ptv/public_transport_stops.geojson\n"
     ]
    }
   ],
   "source": [
    "download_file(URL_TEMPLATE, directory, 'geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4dae56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create public_transport_lines directory\n",
    "directory = '../data/landing/ptv/public_transport_lines'\n",
    "\n",
    "# URL\n",
    "URL_TEMPLATE = \"https://opendata.transport.vic.gov.au/dataset/6d36dfd9-8693-4552-8a03-05eb29a391fd/resource/52e5173e-b5d5-4b65-9b98-89f225fc529c/download/public_transport_lines.geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d081f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved to ../data/landing/ptv/public_transport_lines.geojson\n"
     ]
    }
   ],
   "source": [
    "download_file(URL_TEMPLATE, directory, 'geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ee9819",
   "metadata": {},
   "source": [
    "**Download School Locations Data**\n",
    "\n",
    "We will download school locations from 2023 to 2025. \\\n",
    "There will be one dataset for each of the years we scraped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "782f06b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL\n",
    "schools_23 = \"https://www.education.vic.gov.au/Documents/about/research/datavic/dv346-schoollocations2023.csv\"\n",
    "schools_24 = \"https://www.education.vic.gov.au/Documents/about/research/datavic/dv378_DataVic-SchoolLocations-2024.csv\"\n",
    "schools_25 = \"https://www.education.vic.gov.au/Documents/about/research/datavic/dv402-SchoolLocations2025.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00a37213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved to ../data/landing/schools/school_locations_2023.csv\n",
      "File downloaded and saved to ../data/landing/schools/school_locations_2024.csv\n",
      "File downloaded and saved to ../data/landing/schools/school_locations_2025.csv\n"
     ]
    }
   ],
   "source": [
    "# create 2023 school locations directory\n",
    "directory = '../data/landing/schools/school_locations_2023'\n",
    "download_file(schools_23, directory, 'csv')\n",
    "# create 2024 school locations directory\n",
    "directory = '../data/landing/schools/school_locations_2024'\n",
    "download_file(schools_24, directory, 'csv')\n",
    "# create 2025 school locations directory\n",
    "directory = '../data/landing/schools/school_locations_2025'\n",
    "download_file(schools_25, directory, 'csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c6ac4a",
   "metadata": {},
   "source": [
    "**Download Open Space Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b17f65e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create open_space directory\n",
    "directory = '../data/landing/open_space/open_space'\n",
    "\n",
    "# URL\n",
    "URL_TEMPLATE = \"https://opendata.arcgis.com/datasets/da1c06e3ab6948fcb56de4bb3c722449_0.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "893a68ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved to ../data/landing/open_space/open_space.csv\n"
     ]
    }
   ],
   "source": [
    "download_file(URL_TEMPLATE, directory, 'csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a45011",
   "metadata": {},
   "source": [
    "**Download Moving Annual Rent by Suburb from DFFH (Latest File)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0ae9958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading latest moving annual rent file: moving_annual_median_weekly_rent_by_suburb\n",
      "URL: https://www.dffh.vic.gov.au/moving-annual-rent-suburb-march-quarter-2025-excel\n"
     ]
    }
   ],
   "source": [
    "# Download the latest moving annual rent file (March 2025)\n",
    "# This file contains all historical data from previous quarters and years\n",
    "latest_url = \"https://www.dffh.vic.gov.au/moving-annual-rent-suburb-march-quarter-2025-excel\"\n",
    "filename = \"moving_annual_median_weekly_rent_by_suburb\"\n",
    "\n",
    "print(f\"Downloading latest moving annual rent file: {filename}\")\n",
    "print(f\"URL: {latest_url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5a8618b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved to ../data/landing/moving_annual_rent/moving_annual_median_weekly_rent_by_suburb.xlsx\n",
      "Successfully downloaded latest moving annual rent file!\n"
     ]
    }
   ],
   "source": [
    "# Download the latest moving annual rent file\n",
    "directory = f'../data/landing/moving_annual_rent/{filename}'\n",
    "try:\n",
    "    download_file(latest_url, directory, 'xlsx')\n",
    "    print(\"Successfully downloaded latest moving annual rent file!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error downloading {filename}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b9410e",
   "metadata": {},
   "source": [
    "**Download Victorian Unemployment Rate Data**\n",
    "\n",
    "Scrape monthly unemployment rate data from the Victorian labour market website and aggregate by quarter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73a7e151",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 75\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Create unemployment rate directory\u001b[39;00m\n\u001b[1;32m     74\u001b[0m unemployment_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/landing/unemployment_rate\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 75\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mmakedirs(unemployment_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScraping unemployment data from Victorian labour market website...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     78\u001b[0m unemployment_df \u001b[38;5;241m=\u001b[39m scrape_unemployment_data()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "def scrape_unemployment_data():\n",
    "    \"\"\"\n",
    "    Scrape unemployment data from the Victorian labour market website\n",
    "    and aggregate by quarter taking the average unemployment rate\n",
    "    \"\"\"\n",
    "    url = \"https://djsir-data.github.io/djprecodash/tables/djsir_labour_market\"\n",
    "    \n",
    "    try:\n",
    "        # Make request to the website\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Find the table containing unemployment data\n",
    "        table = soup.find('table')\n",
    "        if not table:\n",
    "            raise ValueError(\"No table found on the webpage\")\n",
    "        \n",
    "        # Extract table data\n",
    "        rows = table.find_all('tr')\n",
    "        data = []\n",
    "        \n",
    "        for row in rows[1:]:  # Skip header row\n",
    "            cells = row.find_all('td')\n",
    "            if len(cells) >= 2:\n",
    "                date_str = cells[0].get_text(strip=True)\n",
    "                unemployment_rate = cells[1].get_text(strip=True)\n",
    "                \n",
    "                # Skip rows with missing data\n",
    "                if date_str and unemployment_rate and unemployment_rate != '':\n",
    "                    data.append({\n",
    "                        'date': date_str,\n",
    "                        'unemployment_rate': float(unemployment_rate)\n",
    "                    })\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        if df.empty:\n",
    "            raise ValueError(\"No data found in the table\")\n",
    "        \n",
    "        # Convert date column to datetime\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        \n",
    "        # Create year and quarter columns\n",
    "        df['year'] = df['date'].dt.year\n",
    "        df['quarter'] = df['date'].dt.quarter\n",
    "        \n",
    "        # Group by year and quarter and calculate average unemployment rate\n",
    "        quarterly_data = df.groupby(['year', 'quarter'])['unemployment_rate'].mean().reset_index()\n",
    "        \n",
    "        # Create a proper date column for quarters\n",
    "        quarterly_data['quarter_date'] = pd.to_datetime(\n",
    "            quarterly_data['year'].astype(str) + '-' + \n",
    "            (quarterly_data['quarter'] * 3).astype(str) + '-01'\n",
    "        )\n",
    "        \n",
    "        # Sort by date\n",
    "        quarterly_data = quarterly_data.sort_values('quarter_date')\n",
    "        \n",
    "        # Select relevant columns for final output\n",
    "        final_data = quarterly_data[['quarter_date', 'year', 'quarter', 'unemployment_rate']].copy()\n",
    "        final_data.columns = ['date', 'year', 'quarter', 'avg_unemployment_rate']\n",
    "        \n",
    "        return final_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping unemployment data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Create unemployment rate directory\n",
    "unemployment_dir = '../data/landing/unemployment_rate'\n",
    "os.makedirs(unemployment_dir, exist_ok=True)\n",
    "\n",
    "print(\"Scraping unemployment data from Victorian labour market website...\")\n",
    "unemployment_df = scrape_unemployment_data()\n",
    "\n",
    "if unemployment_df is not None:\n",
    "    # Save to CSV\n",
    "    output_path = os.path.join(unemployment_dir, 'quarterly_unemployment_rate.csv')\n",
    "    unemployment_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"Successfully scraped and saved unemployment data to {output_path}\")\n",
    "    print(f\"Data contains {len(unemployment_df)} quarterly records\")\n",
    "    print(f\"Date range: {unemployment_df['date'].min()} to {unemployment_df['date'].max()}\")\n",
    "    print(\"\\nFirst 5 records:\")\n",
    "    print(unemployment_df.head())\n",
    "    print(\"\\nLast 5 records:\")\n",
    "    print(unemployment_df.tail())\n",
    "else:\n",
    "    print(\"Failed to scrape unemployment data\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
